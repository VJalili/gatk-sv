---
sidebar_label: Overview
sidebar_position: 2
---

# Pipeline Overview

The pipeline consists of a series of modules that perform the following:
* [Module 00a](#module00a): SV evidence collection, including calls from a configurable set of algorithms (Delly, Manta, MELT, and Wham), read depth (RD), split read positions (SR), and discordant pair positions (PE).
* [Module 00b](#module00b): Dosage bias scoring and ploidy estimation
* [Module 00c](#module00c): Copy number variant calling using cn.MOPS and GATK gCNV; B-allele frequency (BAF) generation; call and evidence aggregation
* [Module 01](#module01): Variant clustering
* [Module 02](#module02): Variant filtering metric generation
* [Module 03](#module03): Variant filtering; outlier exclusion
* [Module 04](#module04): Genotyping
* [Module 05/06](#module0506): Cross-batch integration; complex variant resolution and re-genotyping; vcf cleanup
* [Module 07](#module07): Downstream filtering, including minGQ, batch effect check, outlier samples removal and final recalibration;
* [Module 08](#module08): Annotations, including functional annotation, allele frequency (AF) annotation and AF annotation with external population callsets;
* [Module 09](#module09): Visualization, including scripts that generates IGV screenshots and rd plots.
* Additional modules to be added: de novo and mosaic scripts


## Repository structure

* `/inputs`: Example workflow parameter files for running gCNV training, GATK-SV batch mode, and GATK-SV single-sample mode
* `/dockerfiles`: Resources for building pipeline docker images (see [readme](https://github.com/talkowski-lab/gatk-sv-v1/blob/master/dockerfiles/README.md))
* `/wdl`: WDLs running the pipeline. There is a master WDL for running each module, e.g. `Module01.wdl`.
* `/scripts`: scripts for running tests, building dockers, and analyzing cromwell metadata files
* `/src`: main pipeline scripts
    * `/RdTest`: scripts for depth testing
    * `/sv-pipeline`: various scripts and packages used throughout the pipeline
    * `/svqc`: Python module for checking that pipeline metrics fall within acceptable limits
    * `/svtest`: Python module for generating various summary metrics from module outputs
    * `/svtk`: Python module of tools for SV-related datafile parsing and analysis
    * `/WGD`: whole-genome dosage scoring scripts
* `/test`: WDL test parameter files. Please note that file inputs may not be publicly available.


## Cohort mode

A minimum cohort size of 100 with roughly equal number of males and females is recommended. For modest cohorts (~100-500 samples), the pipeline can be run as a single batch using `GATKSVPipelineBatch.wdl`.

For larger cohorts, samples should be split up into batches of ~100-500 samples. We recommend batching based on overall coverage and dosage score (WGD), which can be generated in [Module 00b](#module00b).

The pipeline should be executed as follows:
* Modules [00a](#module00a) and [00b](#module00b) can be run on arbitrary cohort partitions
* Modules [00c](#module00c), [01](#module01), [02](#module02), and [03](#module03) are run separately per batch
* [Module 04](#module04) is run separately per batch, using filtered variants ([Module 03](#module03) output) combined across all batches
* [Module 05/06](#module0506) and beyond are run on all batches together

Note: [Module 00c](#module00c) requires a [trained gCNV model](#gcnv-training).


## Single-sample mode

`GATKSVPipelineSingleSample.wdl` runs the pipeline on a single sample using a fixed reference panel. An example reference panel containing 156 samples from the [NYGC 1000G Terra workspace](https://app.terra.bio/#workspaces/anvil-datastorage/1000G-high-coverage-2019) is provided with `inputs/GATKSVPipelineSingleSample.ref_panel_1kg.na12878.json`.

Custom reference panels can be generated by running `GATKSVPipelineBatch.wdl` and `trainGCNV.wdl` and using the outputs to replace the following single-sample workflow inputs:

* `GATKSVPipelineSingleSample.ref_ped_file` : `batch.ped` - Manually created (see [data requirements](#requirements))
* `GATKSVPipelineSingleSample.contig_ploidy_model_tar` : `batch-contig-ploidy-model.tar.gz` - gCNV contig ploidy model ([gCNV training](#gcnv-training))
* `GATKSVPipelineSingleSample.gcnv_model_tars` : `batch-model-files-*.tar.gz` - gCNV model tarballs ([gCNV training](#gcnv-training))
* `GATKSVPipelineSingleSample.ref_pesr_disc_files` - `sample.disc.txt.gz` - Paired-end evidence files ([Module 00a](#module00a))
* `GATKSVPipelineSingleSample.ref_pesr_split_files` - `sample.split.txt.gz` - Split read evidence files ([Module 00a](#module00a))
* `GATKSVPipelineSingleSample.ref_panel_bincov_matrix`: `batch.RD.txt.gz` - Read counts matrix ([Module 00c](#module00c))
* `GATKSVPipelineSingleSample.ref_panel_del_bed` : `batch.DEL.bed.gz` - Depth deletion calls ([Module 00c](#module00c))
* `GATKSVPipelineSingleSample.ref_panel_dup_bed` : `batch.DUP.bed.gz` - Depth duplication calls ([Module 00c](#module00c))
* `GATKSVPipelineSingleSample.ref_samples` - Reference panel sample IDs
* `GATKSVPipelineSingleSample.ref_std_manta_vcfs` - `std_XXX.manta.sample.vcf.gz` - Standardized Manta VCFs ([Module 00c](#module00c))
* `GATKSVPipelineSingleSample.ref_std_melt_vcfs` - `std_XXX.melt.sample.vcf.gz` - Standardized Melt VCFs ([Module 00c](#module00c))
* `GATKSVPipelineSingleSample.ref_std_wham_vcfs` - `std_XXX.wham.sample.vcf.gz` - Standardized Wham VCFs ([Module 00c](#module00c))
* `GATKSVPipelineSingleSample.cutoffs` : `batch.cutoffs` - Filtering cutoffs ([Module 03](#module03))
* `GATKSVPipelineSingleSample.genotype_pesr_pesr_sepcutoff` : `genotype_pesr.pesr_sepcutoff.txt` - Genotyping cutoffs ([Module 04](#module04))
* `GATKSVPipelineSingleSample.genotype_pesr_depth_sepcutoff` : `genotype_pesr.depth_sepcutoff.txt` - Genotyping cutoffs ([Module 04](#module04))
* `GATKSVPipelineSingleSample.genotype_depth_pesr_sepcutoff` : `genotype_depth.pesr_sepcutoff.txt` - Genotyping cutoffs ([Module 04](#module04))
* `GATKSVPipelineSingleSample.genotype_depth_depth_sepcutoff` : `genotype_depth.depth_sepcutoff.txt` - Genotyping cutoffs ([Module 04](#module04))
* `GATKSVPipelineSingleSample.PE_metrics` : `pe_metric_file.txt` - Paired-end evidence genotyping metrics ([Module 04](#module04))
* `GATKSVPipelineSingleSample.SR_metrics` : `sr_metric_file.txt` - Split read evidence genotyping metrics ([Module 04](#module04))
* `GATKSVPipelineSingleSample.ref_panel_vcf` : `batch.cleaned.vcf.gz` - Final output VCF ([Module 05/06](#module0506))


## gCNV Training
Both the cohort and single-sample modes use the GATK gCNV depth calling pipeline, which requires a [trained model](#gcnv-training) as input. The samples used for training should be technically homogeneous and similar to the samples to be processed (i.e. same sample type, library prep protocol, sequencer, sequencing center, etc.). The samples to be processed may comprise all or a subset of the training set. For small cohorts, a single gCNV model is usually sufficient. If a cohort contains multiple data sources, we recommend clustering them using the dosage score, and training a separate model for each cluster.



## What's next?

- suggestion 1
- suggestion 2
